ASSIGNMENT 1
1)VARIOUS SOURCES OF BIG DATA:

The various souces of BigData are
        1)Sensor Data--Medical devices,cameras,mobile app usage etc.,
        2)Public Data--Government,census,public finance etc.,
        3)Transactions--payment transactions
        4)Social media--Images,videos,audio,podcasts from facebook,twitter,tumblr etc.,
        5)Machine log data--Event logs,Business process logs,call detail records etc.,
        6)Archives--Archives of scanned documents,statements,insurance forms etc.,
        
2)3V'S OF BIG DATA:

        The 3 V'S of big data are
              1)Volume-Data size
              2)Velocity-Speed of change
              3)Variety-Data sources
              
3)HORIZONTAL SCALING AND VERTICAL SCALING:
        
        HORIZONTAL SCALING:
        Horizontal scaling means that you scale by adding more machines into your pool of resources.
        
        VERTICAL SCALING:
        Vertical scaling means that you scale by adding more power (CPU, RAM) to an existing machine.
        
4)NEED AND WORKING OF HADOOP:

Hadoop is an open source platform that provides excellent data management provision. It is a framework that supports the processing of large data sets in a distributed computing environment. It is designed to expand from single servers to thousands of machines, each providing computation and storage.  Its distributed file system facilitates rapid data transfer rates among nodes and allows the system to continue operating uninterrupted in case of a node failure, which minimizes the risk of catastrophic system failure, even if a significant number of nodes become out of action.
WORKING OF HADOOP:
Hadoop has two main systems
1)Hadoop Distributed File System (HDFS):  the storage system for Hadoop spread out over multiple machines as a means to reduce cost and increase reliability.Data integrity is also carefully monitored by HDFSâ€™s many capabilities. HDFS uses transaction logs and validations to ensure integrity across the cluster.
2)MapReduce engine: the algorithm that filters, sorts and then uses the database input in some way.Hadoop MapReduce is an implementation of the MapReduce algorithm developed and maintained by the Apache Hadoop project. The general idea of the MapReduce algorithm is to break down the data into smaller manageable pieces, process the data in parallel on your distributed cluster, and subsequently combine it into the desired result or output.

